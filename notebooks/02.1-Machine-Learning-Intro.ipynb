{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>This notebook was put together by [Jake Vanderplas](http://www.vanderplas.com). Source and license info is on [GitHub](https://github.com/jakevdp/sklearn_tutorial/).</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Scikit-Learn: Aprendizaje Automático con Python\n",
    "\n",
    "Esta sesión cubrirá los conceptos básicos de Scikit-Learn, un paquete popular que contiene una colección de herramientas para aprendizaje automático escritas en Python. Puedes ver más en [http://scikit-learn.org](http://scikit-learn.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esquema\n",
    "\n",
    "**Objetivo Principal:** Introducir los conceptos centrales del aprendizaje automático y cómo se pueden aplicar en Python utilizando el paquete Scikit-learn.\n",
    "\n",
    "- Definición de aprendizaje automático  \n",
    "- Representación de datos en Scikit-learn  \n",
    "- Introducción a la API de Scikit-learn  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "[Scikit-Learn](http://github.com/scikit-learn/scikit-learn) es un paquete de Python diseñado para proporcionar acceso a algoritmos de aprendizaje automático, a través de una **API limpia y cuidadosamente diseñada**. Ha sido desarrollado por cientos de colaboradores de todo el mundo y se utiliza tanto en la industria como en la academia.\n",
    "\n",
    "Scikit-Learn está construido sobre las bibliotecas de Python [NumPy (Numerical Python)](http://numpy.org) y [SciPy (Scientific Python)](http://scipy.org), que permiten realizar cálculos numéricos y científicos eficientes en memoria dentro de Python. Como tal, Scikit-Learn no está específicamente diseñado para conjuntos de datos extremadamente grandes, aunque existe [trabajo en progreso](https://github.com/ogrisel/parallel_ml_tutorial) en esta área.\n",
    "\n",
    "En esta breve introducción, nos centraremos en cuestiones relacionadas con el procesamiento en memoria de conjuntos de datos pequeños a medianos con Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qué es Machine Learning?\n",
    "\n",
    "En esta sección comenzaremos a explorar los principios básicos del aprendizaje automático.  \n",
    "El aprendizaje automático consiste en construir programas con **parámetros ajustables** (normalmente un array de valores de floats) que se ajustan automáticamente para mejorar su comportamiento **adaptándose a datos previamente observados**.\n",
    "\n",
    "El aprendizaje automático puede considerarse un subcampo de la **inteligencia artificial**, ya que estos algoritmos pueden verse como bloques de construcción para hacer que las computadoras aprendan a comportarse de manera más **inteligente**, **generalizando** de alguna manera, en lugar de simplemente almacenar y recuperar elementos de datos como lo haría un sistema de bases de datos.\n",
    "\n",
    "Aquí analizaremos dos tareas muy sencillas de aprendizaje automático.  \n",
    "La primera es una tarea de **clasificación**: la figura muestra un conjunto de datos bidimensionales, coloreados según dos etiquetas de clase diferentes. Un algoritmo de clasificación puede usarse para trazar un límite divisorio entre los dos grupos de puntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the example plot from the figures directory\n",
    "from fig_code import plot_sgd_separator\n",
    "plot_sgd_separator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto puede parecer una tarea trivial, pero es una versión simple de un concepto muy importante.  \n",
    "Al trazar esta línea de separación, hemos creado un modelo que puede **generalizar** a nuevos datos: si colocas otro punto en el plano que no esté etiquetado, este algoritmo ahora podría **predecir** si es un punto azul o rojo.\n",
    "\n",
    "Si deseas ver el código fuente utilizado para generar esto, puedes abrir el código en el directorio `figures`, o cargar el código usando el comando mágico `%load`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tarea sencilla que examinaremos es una tarea de **regresión**: una simple línea de mejor ajuste para un conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fig_code import plot_linear_regression\n",
    "plot_linear_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, este es un ejemplo de ajustar un modelo a los datos, de modo que el modelo pueda hacer **generalizaciones** sobre nuevos datos. El modelo ha sido **entrenado** con los datos de entrenamiento y puede usarse para predecir el resultado de datos de prueba:  \n",
    "aquí, podríamos tener un valor de `x`, y el modelo nos permitiría predecir el valor de `y`. Una vez más, esto podría parecer un problema trivial, pero es un ejemplo básico de un tipo de operación que es fundamental para las tareas de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de los datos en Scikit-learn\n",
    "\n",
    "El aprendizaje automático trata de crear modelos a partir de datos: por esa razón, comenzaremos discutiendo cómo pueden representarse los datos para que sean entendidos por la computadora. Además, ampliaremos los ejemplos de matplotlib de la sección anterior y mostraremos algunos ejemplos de cómo visualizar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayoría de los algoritmos de aprendizaje automático implementados en scikit-learn esperan que los datos se almacenen en un **arreglo o matriz bidimensional**. Los arrays pueden ser tanto matrices de ``numpy`` como, en algunos casos, matrices dispersas de ``scipy.sparse``.  \n",
    "El tamaño del arreglo se espera que sea `[n_samples, n_features]`.\n",
    "\n",
    "- **n_samples:** El número de muestras: cada muestra es un elemento a procesar (por ejemplo, clasificar).  \n",
    "  Una muestra puede ser un documento, una imagen, un sonido, un video, un objeto astronómico, una fila en una base de datos o archivo CSV, o cualquier cosa que puedas describir con un conjunto fijo de características cuantitativas.\n",
    "  \n",
    "- **n_features:** El número de características o rasgos distintos que se pueden usar para describir cada elemento de manera cuantitativa. Las características suelen tener valores reales, pero en algunos casos pueden ser booleanas o con valores discretos.\n",
    "\n",
    "El número de características debe fijarse de antemano. Sin embargo, puede ser de muy alta dimensionalidad (por ejemplo, millones de características), con la mayoría de ellas siendo ceros para una muestra dada. Este es un caso en el que las matrices de `scipy.sparse` pueden ser útiles, ya que son mucho más eficientes en el uso de memoria que las matrices de numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Layout](images/data-layout.png)\n",
    "\n",
    "(Figura de [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un Ejemplo Sencillo: el Conjunto de Datos Iris\n",
    "\n",
    "Como ejemplo de un conjunto de datos simple, vamos a examinar los datos de iris almacenados por Scikit-learn.  \n",
    "Los datos consisten en mediciones de tres especies diferentes de iris.  \n",
    "Existen tres especies de iris en el conjunto de datos, que podemos visualizar de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display\n",
    "display(Image(filename='images/iris_setosa.jpg'))\n",
    "print(\"Iris Setosa\\n\")\n",
    "\n",
    "display(Image(filename='images/iris_versicolor.jpg'))\n",
    "print(\"Iris Versicolor\\n\")\n",
    "\n",
    "display(Image(filename='images/iris_virginica.jpg'))\n",
    "print(\"Iris Virginica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta Rápida:\n",
    "\n",
    "**Si quisiéramos diseñar un algoritmo para reconocer especies de iris, ¿cómo serían los datos?**\n",
    "\n",
    "Recuerda: necesitamos un arreglo 2D de tamaño `[n_samples x n_features]`.\n",
    "\n",
    "- ¿A qué se referiría `n_samples`?\n",
    "\n",
    "  **`n_samples`** se referiría al número de muestras o ejemplos que tenemos en el conjunto de datos. En este caso, sería el número de flores de iris en el conjunto de datos, donde cada flor representa una muestra.\n",
    "\n",
    "- ¿A qué se referirían `n_features`?\n",
    "\n",
    "  **`n_features`** se referiría al número de características o atributos que usamos para describir cada muestra. En el caso del conjunto de datos Iris, las características podrían ser, por ejemplo, la longitud y el ancho del sépalo, y la longitud y el ancho del pétalo. Es decir, cada flor se describe con estas 4 características.\n",
    "\n",
    "Recuerda que debe haber un número **fijo** de características para cada muestra, y la característica número `i` debe ser de un tipo similar para todas las muestras (por ejemplo, longitud o anchura en unidades de medidas consistentes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando los Datos de Iris con Scikit-Learn\n",
    "\n",
    "Scikit-learn tiene un conjunto de datos muy sencillo sobre estas especies de iris. Los datos consisten en lo siguiente:\n",
    "\n",
    "- **Características en el conjunto de datos Iris**:\n",
    "\n",
    "  1. Longitud del sépalo en cm\n",
    "  2. Ancho del sépalo en cm\n",
    "  3. Longitud del pétalo en cm\n",
    "  4. Ancho del pétalo en cm\n",
    "\n",
    "- **Clases objetivo a predecir**:\n",
    "\n",
    "  1. Iris Setosa\n",
    "  2. Iris Versicolor\n",
    "  3. Iris Virginica\n",
    "  \n",
    "Scikit-learn incluye una copia del archivo CSV de iris junto con una función auxiliar para cargarlo en arreglos de numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = iris.data.shape\n",
    "print((n_samples, n_features))\n",
    "print(iris.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.data.shape)\n",
    "print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos datos son de cuatro dimensiones, pero podemos visualizar dos de las dimensiones a la vez usando un gráfico de dispersión simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio Rápido:\n",
    "\n",
    "**Cambia** `x_index` **y** `y_index` **en el script anterior** y encuentra una combinación de dos parámetros que separen de manera óptima las tres clases.\n",
    "\n",
    "Este ejercicio es una vista previa de la **reducción de dimensionalidad**, que veremos más adelante.\n",
    "\n",
    "---\n",
    "\n",
    "**Sugerencia:** Para separar las clases de manera más clara, prueba combinaciones de características como la longitud del sépalo y el ancho del pétalo. Estas combinaciones suelen ser más efectivas para visualizar y separar las clases en 2D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros Datos Disponibles  \n",
    "Vienen en tres tipos:\n",
    "\n",
    "- **Datos empaquetados:** estos pequeños conjuntos de datos están empaquetados con la instalación de scikit-learn y se pueden descargar usando las herramientas en ``sklearn.datasets.load_*``.\n",
    "- **Datos descargables:** estos conjuntos de datos más grandes están disponibles para su descarga, y scikit-learn incluye herramientas que agilizan este proceso. Estas herramientas se pueden encontrar en ``sklearn.datasets.fetch_*``.\n",
    "- **Datos generados:** existen varios conjuntos de datos generados a partir de modelos basados en una semilla aleatoria. Estos están disponibles en ``sklearn.datasets.make_*``.\n",
    "\n",
    "Puedes explorar los cargadores, descargadores y generadores de conjuntos de datos disponibles usando la funcionalidad de autocompletado de IPython. Después de importar el submódulo ``datasets`` de ``sklearn``, escribe:\n",
    "\n",
    "    datasets.load_ + TAB\n",
    "\n",
    "o\n",
    "\n",
    "    datasets.fetch_ + TAB\n",
    "\n",
    "o\n",
    "\n",
    "    datasets.make_ + TAB\n",
    "\n",
    "para ver una lista de funciones disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type datasets.fetch_<TAB> or datasets.load_<TAB> in IPython to see all possibilities\n",
    "\n",
    "# datasets.fetch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.load_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
